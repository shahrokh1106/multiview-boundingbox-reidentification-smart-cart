{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b2201a-114f-403c-bf4f-76005eded882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import svd\n",
    "from pathlib import Path\n",
    "from keras import applications\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from keras import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    print(gpu) \n",
    "\n",
    "def RGB2Bayer (image):\n",
    "    def isp_it(img):\n",
    "        bayer_norm = (img/255).astype(np.float32)\n",
    "        black_level = 6/255\n",
    "        white_level = 68/255\n",
    "        bayer_norm = (bayer_norm - black_level)/(white_level - black_level)\n",
    "        bayer_norm = bayer_norm*white_level\n",
    "        bayer_norm = np.clip(bayer_norm, 0.0, 1.0)\n",
    "        # red channel\n",
    "        bayer_norm[1::2, 1::2] = bayer_norm[1::2, 1::2]\n",
    "        # blue channel\n",
    "        bayer_norm[::2, ::2] = bayer_norm[::2, ::2]*1.25\n",
    "        bayer_norm = bayer_norm*2.5\n",
    "        bayer_norm = np.clip(bayer_norm, 0, 1)\n",
    "        bayer = np.array(bayer_norm*255, dtype=np.uint8)\n",
    "        img_rgb = cv2.cvtColor(bayer, cv2.COLOR_BAYER_RG2BGR)\n",
    "        return img_rgb\n",
    "    \n",
    "    def reverse_isp_it(img_rgb):\n",
    "        # Assume img_rgb is the output of the isp_it function\n",
    "        # Since we cannot exactly reverse cv2.cvtColor, we start after this step\n",
    "    \n",
    "        # Constants used in the forward process\n",
    "        black_level = 6 / 255\n",
    "        white_level = 68 / 255\n",
    "    \n",
    "        # Reverse the scaling and clipping (from the end of isp_it2)\n",
    "        img_rev = img_rgb.astype(np.float32) / 255\n",
    "        img_rev = np.clip(img_rev, 0, 1) / 2.5\n",
    "    \n",
    "        # Reverse the blue channel adjustment\n",
    "        img_rev[::2, ::2] = img_rev[::2, ::2] / 1.25\n",
    "    \n",
    "        # Reverse the normalization\n",
    "        img_rev = img_rev / white_level\n",
    "        img_rev = (img_rev * (white_level - black_level)) + black_level\n",
    "    \n",
    "        # Assume the output is a Bayer pattern image (but this is a rough approximation)\n",
    "        bayer_approx = np.clip(img_rev * 255, 0, 255).astype(np.uint8)\n",
    "        return bayer_approx\n",
    "    \n",
    "    def approximate_bayer_pattern(img_rgb):\n",
    "        # Assuming img_rgb is the output from reverse_isp_it2\n",
    "    \n",
    "        # Initialize an empty array for the single-channel image\n",
    "        height, width, _ = img_rgb.shape\n",
    "        bayer_pattern = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "        # Approximate the Bayer pattern based on RGGB pattern\n",
    "        bayer_pattern[1::2, 1::2] = img_rgb[1::2, 1::2, 0]  # Red channel\n",
    "        bayer_pattern[::2, ::2] = img_rgb[::2, ::2, 2]    # Blue channel\n",
    "    \n",
    "        # Green channel is interleaved between Red and Blue\n",
    "        bayer_pattern[::2, 1::2] = img_rgb[::2, 1::2, 1]   # Green channel (first row)\n",
    "        bayer_pattern[1::2, ::2] = img_rgb[1::2, ::2, 1]   # Green channel (second row)\n",
    "        return bayer_pattern\n",
    "    \n",
    "    \n",
    "    def convert_rgb_to_bayer(image):\n",
    "        img_rgb = cv2.imread(image, -1)\n",
    "        #img_rgb = cv2.resize(img_rgb, (324,324))    \n",
    "        img_rgb = np.array(255*((img_rgb/255)**(1/0.65)), dtype='uint8')\n",
    "        bayer_approx = reverse_isp_it(img_rgb)\n",
    "        bayer = approximate_bayer_pattern(bayer_approx)\n",
    "        return bayer\n",
    "    return convert_rgb_to_bayer(image) \n",
    "\n",
    "def Bayer2RGB(bayer):\n",
    "    def isp_it2(img):\n",
    "        bayer_norm = (img/255).astype(np.float32)\n",
    "        black_level = 6/255\n",
    "        white_level = 68/255\n",
    "        bayer_norm = (bayer_norm - black_level)/(white_level - black_level)\n",
    "        bayer_norm=bayer_norm*white_level\n",
    "        bayer_norm=np.clip(bayer_norm,0.0,1.0)\n",
    "        #red channel\n",
    "        bayer_norm[1::2,1::2]=bayer_norm[1::2,1::2]\n",
    "        #blue channel\n",
    "        bayer_norm[::2,::2]=bayer_norm[::2,::2]*1.25\n",
    "        bayer_norm=bayer_norm*2.5 # was 2.5\n",
    "        bayer_norm= np.clip(bayer_norm,0,1)\n",
    "        bayer=np.array(bayer_norm*255,dtype=np.uint8)\n",
    "        img_rgb = cv2.cvtColor(bayer, cv2.COLOR_BAYER_RG2RGB)\n",
    "        return img_rgb\n",
    "    linear_img=isp_it2(bayer)\n",
    "    img_gammad=np.array(255*(linear_img/255)**0.65,dtype='uint8')\n",
    "    return img_gammad\n",
    "\n",
    "def show (img, scale_percent = 100, waitKey=-1):\n",
    "    w = int(img.shape[1] * scale_percent / 100)\n",
    "    h = int(img.shape[0] * scale_percent / 100)\n",
    "    image = img.copy()\n",
    "    img = cv2.resize(img, (w, h), interpolation = cv2.INTER_AREA)\n",
    "    cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(waitKey) & 0xFF\n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite(\"image.png\", image)\n",
    "        cv2.destroyAllWindows()     \n",
    "    if k == ord('q'):\n",
    "        cv2.destroyAllWindows()  \n",
    "        return -1\n",
    "        # \n",
    "def draw_bbox (image, od, label):\n",
    "    img = image.copy()\n",
    "    h,w = img.shape[:2]\n",
    "    x1 = int(od[0])\n",
    "    y1 = int(od[1])\n",
    "    x2 = int(od[2])\n",
    "    y2 = int(od[3])\n",
    "        \n",
    "    if label == \"anchor\":\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (255,255,255),2)\n",
    "        cv2.putText(img,label, org=(50,50),fontFace=2,fontScale=1, color=(255,255,255))\n",
    "    if label == \"positive\":\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0),2)\n",
    "        cv2.putText(img,label, org=(50,50),fontFace=2,fontScale=1, color=(0,255,0))\n",
    "    if label == \"negative\":\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,0,255),2)\n",
    "        cv2.putText(img,label, org=(50,50),fontFace=2,fontScale=1, color=(0,0,255))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169e40ab-5bec-42d5-8361-2141e83a261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making feature dataset\n",
    "\n",
    "# interpreter = tf.lite.Interpreter(\"custom_retinanet_mobilenetv1_pretrained_rot_fixed.tflite\",experimental_preserve_all_tensors=True,num_threads=30)\n",
    "# interpreter.allocate_tensors()\n",
    "# input_details = interpreter.get_input_details()\n",
    "# output_details = interpreter.get_output_details()\n",
    "# input_shape = input_details[0]['shape']\n",
    "# scale = input_details[0]['quantization_parameters']['scales'][0]\n",
    "# zero_point = input_details[0]['quantization_parameters']['zero_points'][0]\n",
    "\n",
    "# dataset_path = \"triplet-dataset/\"\n",
    "# folder_paths = [folder_name for folder_name in glob.glob(os.path.join(dataset_path,\"*/\"))]\n",
    "\n",
    "# bbox_dataset = []\n",
    "# rgb_dataset = []\n",
    "# bayer_dataset = []\n",
    "# feature_dataset = [] \n",
    "\n",
    "# for i in tqdm(range(len(folder_paths))):\n",
    "#     # Getting Anchor Data\n",
    "#     anchor_path = folder_paths[i]+\"anchor\"\n",
    "#     anchor_rgb_path = glob.glob(anchor_path+\"/*.png\")[0]\n",
    "#     anchor_bayer = RGB2Bayer(anchor_rgb_path)\n",
    "#     anchor_rgb = Bayer2RGB(anchor_bayer)\n",
    "#     with open(glob.glob(anchor_path+\"/*.json\")[0], 'r') as file:\n",
    "#             anchor_od = json.load(file)\n",
    "#     anchor_bbox = np.asarray(list(anchor_od.values())[1:])*anchor_bayer.shape[0]\n",
    "#     anchor_bbox[0],anchor_bbox[1], anchor_bbox[2],anchor_bbox[3] = anchor_bbox[1],anchor_bbox[0], anchor_bbox[3], anchor_bbox[2]\n",
    "\n",
    "#     positive_path = folder_paths[i]+\"positive\"\n",
    "#     positive_rgb_path = glob.glob(positive_path+\"/*.png\")[0]\n",
    "#     positive_bayer = RGB2Bayer(positive_rgb_path)\n",
    "#     positive_rgb = Bayer2RGB(positive_bayer)\n",
    "#     with open(glob.glob(positive_path+\"/*.json\")[0], 'r') as file:\n",
    "#             positive_od = json.load(file)\n",
    "#     positive_bbox = np.asarray(list(positive_od.values())[1:])*positive_bayer.shape[0]\n",
    "#     positive_bbox[0],positive_bbox[1], positive_bbox[2],positive_bbox[3] = positive_bbox[1],positive_bbox[0], positive_bbox[3], positive_bbox[2]\n",
    "\n",
    "#     negative_path = folder_paths[i]+\"negative\"\n",
    "#     negative_rgb_path = glob.glob(negative_path+\"/*.png\")[0]\n",
    "#     negative_bayer = RGB2Bayer(negative_rgb_path)\n",
    "#     negative_rgb = Bayer2RGB(negative_bayer)\n",
    "#     with open(glob.glob(negative_path+\"/*.json\")[0], 'r') as file:\n",
    "#             negative_od = json.load(file)\n",
    "#     negative_bbox = np.asarray(list(negative_od.values())[1:])*negative_bayer.shape[0]\n",
    "#     negative_bbox[0],negative_bbox[1], negative_bbox[2],negative_bbox[3] = negative_bbox[1],negative_bbox[0], negative_bbox[3], negative_bbox[2]\n",
    "\n",
    "#     bbox_dataset.append([anchor_bbox,positive_bbox,negative_bbox])\n",
    "#     rgb_dataset.append([anchor_rgb,positive_rgb,negative_rgb])\n",
    "#     bayer_dataset.append([anchor_bayer,positive_bayer,negative_bayer])\n",
    "\n",
    "#     anchor_bayer = anchor_bayer / scale\n",
    "#     anchor_bayer = anchor_bayer + zero_point\n",
    "#     anchor_bayer = tf.cast(anchor_bayer,dtype=np.int8)\n",
    "#     anchor_bayer  = tf.expand_dims(anchor_bayer,0)\n",
    "#     anchor_bayer  = tf.expand_dims(anchor_bayer,3)\n",
    "#     interpreter.set_tensor(input_details[0]['index'], anchor_bayer)\n",
    "#     interpreter.invoke()\n",
    "#     anchor_feature_a = interpreter.get_tensor(158)\n",
    "#     anchor_feature_a = tf.cast(tf.image.resize(anchor_feature_a,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     anchor_feature_b = interpreter.get_tensor(171)\n",
    "#     anchor_feature_b = tf.cast(tf.image.resize(anchor_feature_b,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     anchor_feature_c = interpreter.get_tensor(178)\n",
    "#     anchor_feature_c = tf.cast(tf.image.resize(anchor_feature_c,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     anchor_features = tf.concat([anchor_feature_a,anchor_feature_b,anchor_feature_c],3)\n",
    "#     anchor_downscaled_box = np.round(anchor_bbox/8)\n",
    "#     anchor_feature_box = anchor_features[:,int(anchor_downscaled_box[1]):int(anchor_downscaled_box[3]), int(anchor_downscaled_box[0]):int(anchor_downscaled_box[2])]\n",
    "#     anchor_feature_box = tf.image.resize(anchor_feature_box,(10,10),method = 'bilinear')\n",
    "#     anchor_feature_box = tf.squeeze(anchor_feature_box,0)\n",
    "    \n",
    "#     positive_bayer = positive_bayer / scale\n",
    "#     positive_bayer = positive_bayer + zero_point\n",
    "#     positive_bayer = tf.cast(positive_bayer,dtype=np.int8)\n",
    "#     positive_bayer  = tf.expand_dims(positive_bayer,0)\n",
    "#     positive_bayer  = tf.expand_dims(positive_bayer,3)\n",
    "#     interpreter.set_tensor(input_details[0]['index'], positive_bayer)\n",
    "#     interpreter.invoke()\n",
    "#     positive_feature_a = interpreter.get_tensor(158)\n",
    "#     positive_feature_a = tf.cast(tf.image.resize(positive_feature_a,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     positive_feature_b = interpreter.get_tensor(171)\n",
    "#     positive_feature_b = tf.cast(tf.image.resize(positive_feature_b,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     positive_feature_c = interpreter.get_tensor(178)\n",
    "#     positive_feature_c = tf.cast(tf.image.resize(positive_feature_c,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     positive_features = tf.concat([positive_feature_a,positive_feature_b,positive_feature_c],3)\n",
    "#     positive_downscaled_box = np.round(positive_bbox/8)\n",
    "#     positive_feature_box = positive_features[:,int(positive_downscaled_box[1]):int(positive_downscaled_box[3]), int(positive_downscaled_box[0]):int(positive_downscaled_box[2])]\n",
    "#     positive_feature_box = tf.image.resize(positive_feature_box,(10,10),method = 'bilinear')\n",
    "#     positive_feature_box = tf.squeeze(positive_feature_box,0)\n",
    "    \n",
    "#     negative_bayer = negative_bayer / scale\n",
    "#     negative_bayer = negative_bayer + zero_point\n",
    "#     negative_bayer = tf.cast(negative_bayer,dtype=np.int8)\n",
    "#     negative_bayer  = tf.expand_dims(negative_bayer,0)\n",
    "#     negative_bayer  = tf.expand_dims(negative_bayer,3)\n",
    "#     interpreter.set_tensor(input_details[0]['index'], negative_bayer)\n",
    "#     interpreter.invoke()\n",
    "#     negative_feature_a = interpreter.get_tensor(158)\n",
    "#     negative_feature_a = tf.cast(tf.image.resize(negative_feature_a,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     negative_feature_b = interpreter.get_tensor(171)\n",
    "#     negative_feature_b = tf.cast(tf.image.resize(negative_feature_b,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     negative_feature_c = interpreter.get_tensor(178)\n",
    "#     negative_feature_c = tf.cast(tf.image.resize(negative_feature_c,(40,40),method='bilinear'),dtype = np.int8)\n",
    "#     negative_features = tf.concat([ negative_feature_a, negative_feature_b, negative_feature_c],3)\n",
    "#     negative_downscaled_box = np.round(negative_bbox/8)\n",
    "#     negative_feature_box = negative_features[:,int(negative_downscaled_box[1]):int(negative_downscaled_box[3]), int(negative_downscaled_box[0]):int(negative_downscaled_box[2])]\n",
    "#     negative_feature_box = tf.image.resize(negative_feature_box,(10,10),method = 'bilinear')\n",
    "#     negative_feature_box = tf.squeeze(negative_feature_box,0)\n",
    "    \n",
    "#     feature_dataset.append([anchor_feature_box,positive_feature_box,negative_feature_box])\n",
    "\n",
    "# np.save(\"feature_dataset.npy\",feature_dataset)\n",
    "# np.save(\"bayer_dataset.npy\",bayer_dataset)\n",
    "# np.save(\"rgb_dataset.npy\",rgb_dataset)\n",
    "# np.save(\"bbox_dataset.npy\",bbox_dataset)\n",
    "\n",
    "feature_dataset = np.load(\"feature_dataset.npy\")\n",
    "bayer_dataset = np.load(\"bayer_dataset.npy\")\n",
    "rgb_dataset = np.load(\"rgb_dataset.npy\")\n",
    "bbox_dataset = np.load(\"bbox_dataset.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f6a936-98f6-465f-9ed9-1cadf4ecd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the triplet dataset into train, test and val sets\n",
    "X_train, X_val = train_test_split(feature_dataset,test_size=0.2,train_size=0.8,shuffle=True,random_state=40)\n",
    "X_val, X_test = train_test_split(X_val,test_size=0.5,train_size=0.5,shuffle=True,random_state=40)\n",
    "\n",
    "bbx_train, bbx_val = train_test_split(bbox_dataset,test_size=0.2,train_size=0.8,shuffle=True,random_state=40)\n",
    "bbx_val, bbx_test = train_test_split(bbx_val,test_size=0.5,train_size=0.5,shuffle=True,random_state=40)\n",
    "\n",
    "rgb_train, rgb_val = train_test_split(rgb_dataset,test_size=0.2,train_size=0.8,shuffle=True,random_state=40)\n",
    "rgb_val, rgb_test = train_test_split(rgb_val,test_size=0.5,train_size=0.5,shuffle=True,random_state=40)\n",
    "\n",
    "bayer_train, bayer_val = train_test_split(bayer_dataset,test_size=0.2,train_size=0.8,shuffle=True,random_state=40)\n",
    "bayer_val, bayer_test = train_test_split(bayer_val,test_size=0.5,train_size=0.5,shuffle=True,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50bfed96-957e-4272-875b-8a87a58593f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007 251 251\n"
     ]
    }
   ],
   "source": [
    "# checking the dataset\n",
    "rgb_show = rgb_train.copy()\n",
    "bbx_show = bbx_train.copy()\n",
    "for index in range(len(rgb_show)):\n",
    "    anchor_rgb = rgb_show[index][0]\n",
    "    anchor_bbox = bbx_show[index][0]\n",
    "    anchor_rgb = draw_bbox(anchor_rgb, anchor_bbox,label=\"anchor\")\n",
    "    positive_rgb = rgb_show[index][1]\n",
    "    positive_bbox = bbx_show[index][1]\n",
    "    positive_rgb = draw_bbox(positive_rgb, positive_bbox,label=\"positive\")\n",
    "    negative_rgb = rgb_show[index][2]\n",
    "    negative_bbox = bbx_show[index][2]\n",
    "    negative_rgb = draw_bbox(negative_rgb, negative_bbox,label=\"negative\")\n",
    "    # flag = show(np.hstack((anchor_rgb,positive_rgb,negative_rgb)))\n",
    "    # if flag == -1:\n",
    "    #     break\n",
    "print(len(X_train),len(X_val),len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e00d6667-bd23-4e56-a3d1-6bfa02fb93c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " anchor_input (InputLayer)   [(None, 10, 10, 1792)]       0         []                            \n",
      "                                                                                                  \n",
      " positive_input (InputLayer  [(None, 10, 10, 1792)]       0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " negative_input (InputLayer  [(None, 10, 10, 1792)]       0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Embedding (Functional)      (None, 256)                  1096968   ['anchor_input[0][0]',        \n",
      "                                                                     'positive_input[0][0]',      \n",
      "                                                                     'negative_input[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 1)                    0         ['Embedding[0][0]',           \n",
      "                                                                     'Embedding[1][0]',           \n",
      "                                                                     'Embedding[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1096968 (4.18 MB)\n",
      "Trainable params: 1096968 (4.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "41/41 [==============================] - 4s 65ms/step - loss: 0.3379 - val_loss: 0.2845\n",
      "Epoch 2/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.2447 - val_loss: 0.2771\n",
      "Epoch 3/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.2194 - val_loss: 0.2449\n",
      "Epoch 4/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.2018 - val_loss: 0.2404\n",
      "Epoch 5/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1934 - val_loss: 0.2228\n",
      "Epoch 6/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1861 - val_loss: 0.2266\n",
      "Epoch 7/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.1771 - val_loss: 0.2354\n",
      "Epoch 8/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1889 - val_loss: 0.2150\n",
      "Epoch 9/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.1717 - val_loss: 0.2189\n",
      "Epoch 10/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1657 - val_loss: 0.2263\n",
      "Epoch 11/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1606 - val_loss: 0.2037\n",
      "Epoch 12/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1656 - val_loss: 0.2056\n",
      "Epoch 13/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1629 - val_loss: 0.2083\n",
      "Epoch 14/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1520 - val_loss: 0.2081\n",
      "Epoch 15/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1532 - val_loss: 0.1934\n",
      "Epoch 16/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1398 - val_loss: 0.2056\n",
      "Epoch 17/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1448 - val_loss: 0.2025\n",
      "Epoch 18/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.1301 - val_loss: 0.1922\n",
      "Epoch 19/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1284 - val_loss: 0.1784\n",
      "Epoch 20/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.1282 - val_loss: 0.1990\n",
      "Epoch 21/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.1252 - val_loss: 0.1794\n",
      "Epoch 22/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.1251 - val_loss: 0.1780\n",
      "Epoch 23/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1142 - val_loss: 0.1871\n",
      "Epoch 24/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1094 - val_loss: 0.1938\n",
      "Epoch 25/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1093 - val_loss: 0.1733\n",
      "Epoch 26/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.1194 - val_loss: 0.1844\n",
      "Epoch 27/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1113 - val_loss: 0.1791\n",
      "Epoch 28/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1011 - val_loss: 0.1875\n",
      "Epoch 29/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0949 - val_loss: 0.1804\n",
      "Epoch 30/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0976 - val_loss: 0.1950\n",
      "Epoch 31/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.0906 - val_loss: 0.1786\n",
      "Epoch 32/500\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.0882 - val_loss: 0.1684\n",
      "Epoch 33/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0848 - val_loss: 0.1682\n",
      "Epoch 34/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0830 - val_loss: 0.1728\n",
      "Epoch 35/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0859 - val_loss: 0.1750\n",
      "Epoch 36/500\n",
      "41/41 [==============================] - 2s 51ms/step - loss: 0.0903 - val_loss: 0.1749\n",
      "Epoch 37/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0757 - val_loss: 0.1659\n",
      "Epoch 38/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0752 - val_loss: 0.1643\n",
      "Epoch 39/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0743 - val_loss: 0.1696\n",
      "Epoch 40/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0685 - val_loss: 0.1731\n",
      "Epoch 41/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0695 - val_loss: 0.1635\n",
      "Epoch 42/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0650 - val_loss: 0.1692\n",
      "Epoch 43/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.0689 - val_loss: 0.1670\n",
      "Epoch 44/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0618 - val_loss: 0.1625\n",
      "Epoch 45/500\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.0602 - val_loss: 0.1684\n",
      "Epoch 46/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0612 - val_loss: 0.1617\n",
      "Epoch 47/500\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.0559 - val_loss: 0.1683\n",
      "Epoch 48/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0527 - val_loss: 0.1554\n",
      "Epoch 49/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0446 - val_loss: 0.1574\n",
      "Epoch 50/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0484 - val_loss: 0.1664\n",
      "Epoch 51/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0504 - val_loss: 0.1635\n",
      "Epoch 52/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0451 - val_loss: 0.1514\n",
      "Epoch 53/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.0398 - val_loss: 0.1460\n",
      "Epoch 54/500\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0397 - val_loss: 0.1682\n",
      "Epoch 55/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0407 - val_loss: 0.1410\n",
      "Epoch 56/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0330 - val_loss: 0.1527\n",
      "Epoch 57/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0377 - val_loss: 0.1556\n",
      "Epoch 58/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0372 - val_loss: 0.1442\n",
      "Epoch 59/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0282 - val_loss: 0.1443\n",
      "Epoch 60/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0285 - val_loss: 0.1394\n",
      "Epoch 61/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0262 - val_loss: 0.1403\n",
      "Epoch 62/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0231 - val_loss: 0.1506\n",
      "Epoch 63/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0260 - val_loss: 0.1382\n",
      "Epoch 64/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0281 - val_loss: 0.1396\n",
      "Epoch 65/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0225 - val_loss: 0.1394\n",
      "Epoch 66/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0278 - val_loss: 0.1396\n",
      "Epoch 67/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0238 - val_loss: 0.1316\n",
      "Epoch 68/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0208 - val_loss: 0.1280\n",
      "Epoch 69/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0287 - val_loss: 0.1401\n",
      "Epoch 70/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0196 - val_loss: 0.1290\n",
      "Epoch 71/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0203 - val_loss: 0.1233\n",
      "Epoch 72/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0149 - val_loss: 0.1262\n",
      "Epoch 73/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0141 - val_loss: 0.1249\n",
      "Epoch 74/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0138 - val_loss: 0.1233\n",
      "Epoch 75/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.0126 - val_loss: 0.1326\n",
      "Epoch 76/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0191 - val_loss: 0.1259\n",
      "Epoch 77/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0128 - val_loss: 0.1275\n",
      "Epoch 78/500\n",
      "41/41 [==============================] - 2s 57ms/step - loss: 0.0120 - val_loss: 0.1236\n",
      "Epoch 79/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0146 - val_loss: 0.1321\n",
      "Epoch 80/500\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0146 - val_loss: 0.1229\n",
      "Epoch 81/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0100 - val_loss: 0.1253\n",
      "Epoch 82/500\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 0.0106 - val_loss: 0.1226\n",
      "Epoch 83/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0092 - val_loss: 0.1318\n",
      "Epoch 84/500\n",
      "41/41 [==============================] - 2s 59ms/step - loss: 0.0116 - val_loss: 0.1249\n",
      "Epoch 85/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0107 - val_loss: 0.1241\n",
      "Epoch 86/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.0118 - val_loss: 0.1228\n",
      "Epoch 87/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0076 - val_loss: 0.1176\n",
      "Epoch 88/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.0075 - val_loss: 0.1187\n",
      "Epoch 89/500\n",
      "41/41 [==============================] - 3s 75ms/step - loss: 0.0103 - val_loss: 0.1236\n",
      "Epoch 90/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0091 - val_loss: 0.1173\n",
      "Epoch 91/500\n",
      "41/41 [==============================] - 2s 50ms/step - loss: 0.0067 - val_loss: 0.1149\n",
      "Epoch 92/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.0076 - val_loss: 0.1299\n",
      "Epoch 93/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.0074 - val_loss: 0.1175\n",
      "Epoch 94/500\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 0.0064 - val_loss: 0.1127\n",
      "Epoch 95/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0073 - val_loss: 0.1214\n",
      "Epoch 96/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0061 - val_loss: 0.1158\n",
      "Epoch 97/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0064 - val_loss: 0.1176\n",
      "Epoch 98/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0064 - val_loss: 0.1180\n",
      "Epoch 99/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0049 - val_loss: 0.1116\n",
      "Epoch 100/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0043 - val_loss: 0.1139\n",
      "Epoch 101/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0034 - val_loss: 0.1124\n",
      "Epoch 102/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0035 - val_loss: 0.1175\n",
      "Epoch 103/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0054 - val_loss: 0.1195\n",
      "Epoch 104/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0058 - val_loss: 0.1150\n",
      "Epoch 105/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0055 - val_loss: 0.1150\n",
      "Epoch 106/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0040 - val_loss: 0.1159\n",
      "Epoch 107/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0065 - val_loss: 0.1299\n",
      "Epoch 108/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0082 - val_loss: 0.1094\n",
      "Epoch 109/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0041 - val_loss: 0.1097\n",
      "Epoch 110/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0055 - val_loss: 0.1204\n",
      "Epoch 111/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0084 - val_loss: 0.1147\n",
      "Epoch 112/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0085 - val_loss: 0.1284\n",
      "Epoch 113/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0053 - val_loss: 0.1159\n",
      "Epoch 114/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0044 - val_loss: 0.1128\n",
      "Epoch 115/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0051 - val_loss: 0.1144\n",
      "Epoch 116/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0026 - val_loss: 0.1100\n",
      "Epoch 117/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0038 - val_loss: 0.1135\n",
      "Epoch 118/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0111 - val_loss: 0.1217\n",
      "Epoch 119/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0036 - val_loss: 0.1176\n",
      "Epoch 120/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0024 - val_loss: 0.1131\n",
      "Epoch 121/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0019 - val_loss: 0.1096\n",
      "Epoch 122/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0036 - val_loss: 0.1133\n",
      "Epoch 123/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0061 - val_loss: 0.1169\n",
      "Epoch 124/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0024 - val_loss: 0.1165\n",
      "Epoch 125/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0022 - val_loss: 0.1109\n",
      "Epoch 126/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0029 - val_loss: 0.1067\n",
      "Epoch 127/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0074 - val_loss: 0.1095\n",
      "Epoch 128/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0016 - val_loss: 0.1062\n",
      "Epoch 129/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0035 - val_loss: 0.1084\n",
      "Epoch 130/500\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.0067 - val_loss: 0.1078\n",
      "Epoch 131/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0034 - val_loss: 0.1127\n",
      "Epoch 132/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0017 - val_loss: 0.1062\n",
      "Epoch 133/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0014 - val_loss: 0.1060\n",
      "Epoch 134/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0016 - val_loss: 0.1047\n",
      "Epoch 135/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0020 - val_loss: 0.1103\n",
      "Epoch 136/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 9.1133e-04 - val_loss: 0.1079\n",
      "Epoch 137/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0011 - val_loss: 0.1103\n",
      "Epoch 138/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0024 - val_loss: 0.1027\n",
      "Epoch 139/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0032 - val_loss: 0.1046\n",
      "Epoch 140/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0019 - val_loss: 0.1040\n",
      "Epoch 141/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0011 - val_loss: 0.0998\n",
      "Epoch 142/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 8.6444e-04 - val_loss: 0.1032\n",
      "Epoch 143/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0013 - val_loss: 0.1062\n",
      "Epoch 144/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0040 - val_loss: 0.1096\n",
      "Epoch 145/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0028 - val_loss: 0.1051\n",
      "Epoch 146/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0039 - val_loss: 0.1107\n",
      "Epoch 147/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0038 - val_loss: 0.1057\n",
      "Epoch 148/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 8.7735e-04 - val_loss: 0.1028\n",
      "Epoch 149/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0011 - val_loss: 0.1111\n",
      "Epoch 150/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0014 - val_loss: 0.1063\n",
      "Epoch 151/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0054 - val_loss: 0.1063\n",
      "Epoch 152/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 7.8041e-04 - val_loss: 0.1052\n",
      "Epoch 153/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 8.6663e-04 - val_loss: 0.1028\n",
      "Epoch 154/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0015 - val_loss: 0.1036\n",
      "Epoch 155/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0018 - val_loss: 0.1023\n",
      "Epoch 156/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.4836e-04 - val_loss: 0.1078\n",
      "Epoch 157/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0016 - val_loss: 0.1038\n",
      "Epoch 158/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0012 - val_loss: 0.1101\n",
      "Epoch 159/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0013 - val_loss: 0.1064\n",
      "Epoch 160/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 7.3497e-04 - val_loss: 0.1065\n",
      "Epoch 161/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.5050e-04 - val_loss: 0.1042\n",
      "Epoch 162/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0018 - val_loss: 0.1052\n",
      "Epoch 163/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0011 - val_loss: 0.1035\n",
      "Epoch 164/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0020 - val_loss: 0.1061\n",
      "Epoch 165/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0029 - val_loss: 0.1062\n",
      "Epoch 166/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0052 - val_loss: 0.1109\n",
      "Epoch 167/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 7.8108e-04 - val_loss: 0.1068\n",
      "Epoch 168/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.2801e-04 - val_loss: 0.1093\n",
      "Epoch 169/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0031 - val_loss: 0.1076\n",
      "Epoch 170/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0038 - val_loss: 0.1280\n",
      "Epoch 171/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0035 - val_loss: 0.1029\n",
      "Epoch 172/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 9.7551e-04 - val_loss: 0.1058\n",
      "Epoch 173/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 7.2084e-04 - val_loss: 0.1050\n",
      "Epoch 174/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0019 - val_loss: 0.1044\n",
      "Epoch 175/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0014 - val_loss: 0.1108\n",
      "Epoch 176/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 9.1426e-04 - val_loss: 0.1055\n",
      "Epoch 177/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 5.3239e-04 - val_loss: 0.0972\n",
      "Epoch 178/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 9.7390e-04 - val_loss: 0.1072\n",
      "Epoch 179/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.9551e-04 - val_loss: 0.1009\n",
      "Epoch 180/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 8.1455e-04 - val_loss: 0.1112\n",
      "Epoch 181/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0030 - val_loss: 0.1065\n",
      "Epoch 182/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0031 - val_loss: 0.1083\n",
      "Epoch 183/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0014 - val_loss: 0.1044\n",
      "Epoch 184/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0035 - val_loss: 0.1271\n",
      "Epoch 185/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0033 - val_loss: 0.1052\n",
      "Epoch 186/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0021 - val_loss: 0.1062\n",
      "Epoch 187/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0017 - val_loss: 0.1112\n",
      "Epoch 188/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0014 - val_loss: 0.1107\n",
      "Epoch 189/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0011 - val_loss: 0.1093\n",
      "Epoch 190/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0022 - val_loss: 0.1131\n",
      "Epoch 191/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0014 - val_loss: 0.1042\n",
      "Epoch 192/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0013 - val_loss: 0.1033\n",
      "Epoch 193/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0011 - val_loss: 0.1069\n",
      "Epoch 194/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 5.4763e-04 - val_loss: 0.1070\n",
      "Epoch 195/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0034 - val_loss: 0.1081\n",
      "Epoch 196/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0018 - val_loss: 0.1016\n",
      "Epoch 197/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0025 - val_loss: 0.1305\n",
      "Epoch 198/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0027 - val_loss: 0.1101\n",
      "Epoch 199/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0016 - val_loss: 0.1033\n",
      "Epoch 200/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.0544e-04 - val_loss: 0.1044\n",
      "Epoch 201/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0011 - val_loss: 0.1061\n",
      "Epoch 202/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.5292e-04 - val_loss: 0.1019\n",
      "Epoch 203/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.7571e-04 - val_loss: 0.0989\n",
      "Epoch 204/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.3423e-04 - val_loss: 0.1017\n",
      "Epoch 205/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 4.7553e-04 - val_loss: 0.1079\n",
      "Epoch 206/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0015 - val_loss: 0.1071\n",
      "Epoch 207/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0012 - val_loss: 0.1011\n",
      "Epoch 208/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 8.7098e-04 - val_loss: 0.1107\n",
      "Epoch 209/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0017 - val_loss: 0.1049\n",
      "Epoch 210/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.6870e-04 - val_loss: 0.1018\n",
      "Epoch 211/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 5.1765e-04 - val_loss: 0.0987\n",
      "Epoch 212/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0011 - val_loss: 0.1080\n",
      "Epoch 213/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0018 - val_loss: 0.1129\n",
      "Epoch 214/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0021 - val_loss: 0.1069\n",
      "Epoch 215/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0024 - val_loss: 0.1077\n",
      "Epoch 216/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0012 - val_loss: 0.1132\n",
      "Epoch 217/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 7.0691e-04 - val_loss: 0.1072\n",
      "Epoch 218/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 8.3002e-04 - val_loss: 0.1052\n",
      "Epoch 219/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0048 - val_loss: 0.1163\n",
      "Epoch 220/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0015 - val_loss: 0.1057\n",
      "Epoch 221/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 7.3413e-04 - val_loss: 0.1044\n",
      "Epoch 222/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 0.1028\n",
      "Epoch 223/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0010 - val_loss: 0.1079\n",
      "Epoch 224/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 7.1963e-04 - val_loss: 0.1067\n",
      "Epoch 225/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 7.9919e-04 - val_loss: 0.1087\n",
      "Epoch 226/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.8560e-04 - val_loss: 0.1057\n",
      "Epoch 227/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.8045e-04 - val_loss: 0.0989\n",
      "Epoch 228/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 3.6475e-04 - val_loss: 0.0987\n",
      "Epoch 229/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.9676e-04 - val_loss: 0.0983\n",
      "Epoch 230/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 4.4928e-04 - val_loss: 0.1017\n",
      "Epoch 231/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0012 - val_loss: 0.1233\n",
      "Epoch 232/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0044 - val_loss: 0.1061\n",
      "Epoch 233/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0023 - val_loss: 0.1022\n",
      "Epoch 234/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 8.3826e-04 - val_loss: 0.1046\n",
      "Epoch 235/500\n",
      "41/41 [==============================] - 2s 36ms/step - loss: 0.0017 - val_loss: 0.1031\n",
      "Epoch 236/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 9.2795e-04 - val_loss: 0.1076\n",
      "Epoch 237/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.9768e-04 - val_loss: 0.1071\n",
      "Epoch 238/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.0010 - val_loss: 0.1027\n",
      "Epoch 239/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0012 - val_loss: 0.1026\n",
      "Epoch 240/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.8036e-04 - val_loss: 0.1003\n",
      "Epoch 241/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.9314e-04 - val_loss: 0.1015\n",
      "Epoch 242/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 3.4079e-04 - val_loss: 0.1037\n",
      "Epoch 243/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0013 - val_loss: 0.1111\n",
      "Epoch 244/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0020 - val_loss: 0.1044\n",
      "Epoch 245/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.1907e-04 - val_loss: 0.1064\n",
      "Epoch 246/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.1196e-04 - val_loss: 0.1021\n",
      "Epoch 247/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0016 - val_loss: 0.1029\n",
      "Epoch 248/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 4.1639e-04 - val_loss: 0.1057\n",
      "Epoch 249/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.3585e-04 - val_loss: 0.1056\n",
      "Epoch 250/500\n",
      "41/41 [==============================] - 2s 36ms/step - loss: 0.0012 - val_loss: 0.0968\n",
      "Epoch 251/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0020 - val_loss: 0.1034\n",
      "Epoch 252/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0016 - val_loss: 0.1020\n",
      "Epoch 253/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 7.4903e-04 - val_loss: 0.0970\n",
      "Epoch 254/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.9327e-04 - val_loss: 0.0979\n",
      "Epoch 255/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 5.8505e-04 - val_loss: 0.1000\n",
      "Epoch 256/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 2.5882e-04 - val_loss: 0.0984\n",
      "Epoch 257/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 4.4417e-04 - val_loss: 0.0979\n",
      "Epoch 258/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.8886e-04 - val_loss: 0.0986\n",
      "Epoch 259/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 4.3305e-04 - val_loss: 0.1117\n",
      "Epoch 260/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0013 - val_loss: 0.1009\n",
      "Epoch 261/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0056 - val_loss: 0.1068\n",
      "Epoch 262/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0038 - val_loss: 0.1038\n",
      "Epoch 263/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.8280e-04 - val_loss: 0.0984\n",
      "Epoch 264/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 8.9547e-04 - val_loss: 0.1020\n",
      "Epoch 265/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.3631e-04 - val_loss: 0.1015\n",
      "Epoch 266/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.4958e-04 - val_loss: 0.0964\n",
      "Epoch 267/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.0177e-04 - val_loss: 0.0993\n",
      "Epoch 268/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.8770e-04 - val_loss: 0.0955\n",
      "Epoch 269/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.5154e-04 - val_loss: 0.0954\n",
      "Epoch 270/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 4.5089e-05 - val_loss: 0.0962\n",
      "Epoch 271/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 6.4683e-04 - val_loss: 0.0990\n",
      "Epoch 272/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 8.4020e-05 - val_loss: 0.0998\n",
      "Epoch 273/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0013 - val_loss: 0.1003\n",
      "Epoch 274/500\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0027 - val_loss: 0.1106\n",
      "Epoch 275/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0014 - val_loss: 0.1008\n",
      "Epoch 276/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.4402e-04 - val_loss: 0.1014\n",
      "Epoch 277/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.6980e-04 - val_loss: 0.1027\n",
      "Epoch 278/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.3810e-04 - val_loss: 0.1027\n",
      "Epoch 279/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 5.8062e-04 - val_loss: 0.1036\n",
      "Epoch 280/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 0.1103\n",
      "Epoch 281/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 0.1036\n",
      "Epoch 282/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.8319e-05 - val_loss: 0.1013\n",
      "Epoch 283/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.0701e-04 - val_loss: 0.1037\n",
      "Epoch 284/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.4457e-04 - val_loss: 0.1056\n",
      "Epoch 285/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.0352e-04 - val_loss: 0.1008\n",
      "Epoch 286/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0035 - val_loss: 0.1042\n",
      "Epoch 287/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 7.7702e-04 - val_loss: 0.1045\n",
      "Epoch 288/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.0239e-04 - val_loss: 0.1012\n",
      "Epoch 289/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 1.5022e-04 - val_loss: 0.1025\n",
      "Epoch 290/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 3.2289e-05 - val_loss: 0.1039\n",
      "Epoch 291/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 7.3650e-04 - val_loss: 0.1044\n",
      "Epoch 292/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0036 - val_loss: 0.1077\n",
      "Epoch 293/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.8123e-04 - val_loss: 0.1027\n",
      "Epoch 294/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.6409e-04 - val_loss: 0.1030\n",
      "Epoch 295/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.8493e-04 - val_loss: 0.1086\n",
      "Epoch 296/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.7959e-04 - val_loss: 0.1026\n",
      "Epoch 297/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.8206e-04 - val_loss: 0.1066\n",
      "Epoch 298/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 5.7379e-04 - val_loss: 0.1069\n",
      "Epoch 299/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 4.3460e-04 - val_loss: 0.1089\n",
      "Epoch 300/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0011 - val_loss: 0.1077\n",
      "Epoch 301/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0013 - val_loss: 0.1099\n",
      "Epoch 302/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 3.9749e-04 - val_loss: 0.1071\n",
      "Epoch 303/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.2359e-04 - val_loss: 0.1069\n",
      "Epoch 304/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0032 - val_loss: 0.1154\n",
      "Epoch 305/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.6439e-04 - val_loss: 0.1107\n",
      "Epoch 306/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0012 - val_loss: 0.1064\n",
      "Epoch 307/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.0088 - val_loss: 0.1058\n",
      "Epoch 308/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 5.4828e-04 - val_loss: 0.1028\n",
      "Epoch 309/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.6014e-04 - val_loss: 0.1016\n",
      "Epoch 310/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.3503e-04 - val_loss: 0.0984\n",
      "Epoch 311/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 5.8909e-05 - val_loss: 0.0954\n",
      "Epoch 312/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.2417e-04 - val_loss: 0.0960\n",
      "Epoch 313/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1.0866e-04 - val_loss: 0.0983\n",
      "Epoch 314/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 4.5980e-04 - val_loss: 0.0989\n",
      "Epoch 315/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 2.2092e-04 - val_loss: 0.1053\n",
      "Epoch 316/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 1.8648e-04 - val_loss: 0.0984\n",
      "Epoch 317/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.6879e-04 - val_loss: 0.0969\n",
      "Epoch 318/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.9125e-04 - val_loss: 0.0994\n",
      "Epoch 319/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.6960e-04 - val_loss: 0.0943\n",
      "Epoch 320/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.9059e-04 - val_loss: 0.0975\n",
      "Epoch 321/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.5322e-04 - val_loss: 0.0969\n",
      "Epoch 322/500\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 2.7501e-04 - val_loss: 0.0981\n",
      "Epoch 323/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.5961e-06 - val_loss: 0.0981\n",
      "Epoch 324/500\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 3.3564e-04 - val_loss: 0.1022\n",
      "Epoch 325/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 7.5992e-04 - val_loss: 0.0980\n",
      "Epoch 326/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 2.6763e-04 - val_loss: 0.1010\n",
      "Epoch 327/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.0474e-04 - val_loss: 0.0976\n",
      "Epoch 328/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.0442e-04 - val_loss: 0.0984\n",
      "Epoch 329/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.1777e-05 - val_loss: 0.0971\n",
      "Epoch 330/500\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 1.6197e-04 - val_loss: 0.0998\n",
      "Epoch 331/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.5451e-05 - val_loss: 0.1019\n",
      "Epoch 332/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0014 - val_loss: 0.1060\n",
      "Epoch 333/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 4.8550e-04 - val_loss: 0.0999\n",
      "Epoch 334/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.9570e-04 - val_loss: 0.1004\n",
      "Epoch 335/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 9.1905e-05 - val_loss: 0.1018\n",
      "Epoch 336/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.2710e-04 - val_loss: 0.1056\n",
      "Epoch 337/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.3895e-04 - val_loss: 0.1010\n",
      "Epoch 338/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 3.9554e-04 - val_loss: 0.1035\n",
      "Epoch 339/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0012 - val_loss: 0.1011\n",
      "Epoch 340/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0016 - val_loss: 0.1023\n",
      "Epoch 341/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 4.2724e-04 - val_loss: 0.0995\n",
      "Epoch 342/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 7.0991e-04 - val_loss: 0.1063\n",
      "Epoch 343/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 0.0011 - val_loss: 0.1049\n",
      "Epoch 344/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 2.5808e-04 - val_loss: 0.1029\n",
      "Epoch 345/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 5.7920e-04 - val_loss: 0.1034\n",
      "Epoch 346/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0013 - val_loss: 0.1029\n",
      "Epoch 347/500\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 3.0436e-04 - val_loss: 0.0992\n",
      "Epoch 348/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 1.2670e-04 - val_loss: 0.1004\n",
      "Epoch 349/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 2.6656e-04 - val_loss: 0.1002\n",
      "Epoch 350/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.5954e-04 - val_loss: 0.1040\n",
      "Epoch 351/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 4.3806e-04 - val_loss: 0.1087\n",
      "Epoch 352/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.6286e-04 - val_loss: 0.0989\n",
      "Epoch 353/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 8.6663e-04 - val_loss: 0.1087\n",
      "Epoch 354/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0014 - val_loss: 0.0980\n",
      "Epoch 355/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 9.1140e-04 - val_loss: 0.1128\n",
      "Epoch 356/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 6.4704e-04 - val_loss: 0.1028\n",
      "Epoch 357/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.4708e-04 - val_loss: 0.0998\n",
      "Epoch 358/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 3.1578e-04 - val_loss: 0.0996\n",
      "Epoch 359/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.0204e-04 - val_loss: 0.1023\n",
      "Epoch 360/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0032 - val_loss: 0.0958\n",
      "Epoch 361/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.3820e-04 - val_loss: 0.0948\n",
      "Epoch 362/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 4.3978e-04 - val_loss: 0.0931\n",
      "Epoch 363/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.5214e-04 - val_loss: 0.0957\n",
      "Epoch 364/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 9.4448e-04 - val_loss: 0.1039\n",
      "Epoch 365/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 5.3517e-04 - val_loss: 0.1019\n",
      "Epoch 366/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 2.2375e-04 - val_loss: 0.1009\n",
      "Epoch 367/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0018 - val_loss: 0.1083\n",
      "Epoch 368/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.0015 - val_loss: 0.0944\n",
      "Epoch 369/500\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 1.5964e-04 - val_loss: 0.0937\n",
      "Epoch 370/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.3358e-04 - val_loss: 0.0959\n",
      "Epoch 371/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 1.7239e-04 - val_loss: 0.0983\n",
      "Epoch 372/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 2.4517e-04 - val_loss: 0.0983\n",
      "Epoch 373/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.8275e-04 - val_loss: 0.0997\n",
      "Epoch 374/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.5786e-04 - val_loss: 0.0983\n",
      "Epoch 375/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 7.6048e-05 - val_loss: 0.0965\n",
      "Epoch 376/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.1421e-04 - val_loss: 0.0964\n",
      "Epoch 377/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.1687e-04 - val_loss: 0.0981\n",
      "Epoch 378/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.4994e-04 - val_loss: 0.1066\n",
      "Epoch 379/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 4.1321e-04 - val_loss: 0.1053\n",
      "Epoch 380/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 7.2818e-04 - val_loss: 0.0993\n",
      "Epoch 381/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0019 - val_loss: 0.1098\n",
      "Epoch 382/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0014 - val_loss: 0.1014\n",
      "Epoch 383/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 3.7797e-04 - val_loss: 0.0997\n",
      "Epoch 384/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 4.8830e-04 - val_loss: 0.1047\n",
      "Epoch 385/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.2697e-04 - val_loss: 0.1029\n",
      "Epoch 386/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 9.7483e-04 - val_loss: 0.0973\n",
      "Epoch 387/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 7.0609e-04 - val_loss: 0.0949\n",
      "Epoch 388/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0012 - val_loss: 0.1159\n",
      "Epoch 389/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 9.1730e-04 - val_loss: 0.0961\n",
      "Epoch 390/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 2.5260e-04 - val_loss: 0.0987\n",
      "Epoch 391/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.4767e-04 - val_loss: 0.1011\n",
      "Epoch 392/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.4996e-04 - val_loss: 0.0960\n",
      "Epoch 393/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 2.8583e-04 - val_loss: 0.0953\n",
      "Epoch 394/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 8.2235e-04 - val_loss: 0.1006\n",
      "Epoch 395/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 9.1006e-04 - val_loss: 0.0982\n",
      "Epoch 396/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 4.7070e-04 - val_loss: 0.0980\n",
      "Epoch 397/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.3309e-04 - val_loss: 0.0968\n",
      "Epoch 398/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0014 - val_loss: 0.0990\n",
      "Epoch 399/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.6321e-04 - val_loss: 0.1091\n",
      "Epoch 400/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 5.9273e-04 - val_loss: 0.0974\n",
      "Epoch 401/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.5929e-04 - val_loss: 0.0998\n",
      "Epoch 402/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.4041e-04 - val_loss: 0.1023\n",
      "Epoch 403/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 5.1079e-04 - val_loss: 0.1022\n",
      "Epoch 404/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 6.5870e-04 - val_loss: 0.0992\n",
      "Epoch 405/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 2.5844e-04 - val_loss: 0.0990\n",
      "Epoch 406/500\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 3.1611e-04 - val_loss: 0.1019\n",
      "Epoch 407/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 5.6917e-04 - val_loss: 0.1043\n",
      "Epoch 408/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0021 - val_loss: 0.1090\n",
      "Epoch 409/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.2408e-04 - val_loss: 0.1005\n",
      "Epoch 410/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.9428e-04 - val_loss: 0.0991\n",
      "Epoch 411/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.3529e-04 - val_loss: 0.1043\n",
      "Epoch 412/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 4.9132e-04 - val_loss: 0.0992\n",
      "Epoch 413/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 2.2721e-04 - val_loss: 0.0960\n",
      "Epoch 414/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0018 - val_loss: 0.0990\n",
      "Epoch 415/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 3.1945e-04 - val_loss: 0.1003\n",
      "Epoch 416/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 1.3232e-04 - val_loss: 0.0989\n",
      "Epoch 417/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1.0586e-04 - val_loss: 0.1001\n",
      "Epoch 418/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 4.7286e-05 - val_loss: 0.1003\n",
      "Epoch 419/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1.5383e-04 - val_loss: 0.1032\n",
      "Epoch 420/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 3.5806e-04 - val_loss: 0.1060\n",
      "Epoch 421/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 5.8458e-04 - val_loss: 0.1045\n",
      "Epoch 422/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 2.7025e-04 - val_loss: 0.1049\n",
      "Epoch 423/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 6.3202e-04 - val_loss: 0.1010\n",
      "Epoch 424/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 6.3909e-04 - val_loss: 0.1007\n",
      "Epoch 425/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 4.5768e-04 - val_loss: 0.1089\n",
      "Epoch 426/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 5.0482e-04 - val_loss: 0.1079\n",
      "Epoch 427/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 7.5163e-04 - val_loss: 0.1060\n",
      "Epoch 428/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0014 - val_loss: 0.1070\n",
      "Epoch 429/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0013 - val_loss: 0.0996\n",
      "Epoch 430/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 8.1154e-04 - val_loss: 0.1018\n",
      "Epoch 431/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0012 - val_loss: 0.1058\n",
      "Epoch 432/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 3.9031e-04 - val_loss: 0.1004\n",
      "Epoch 433/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.2140e-04 - val_loss: 0.1013\n",
      "Epoch 434/500\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 4.5765e-05 - val_loss: 0.0991\n",
      "Epoch 435/500\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 4.7340e-04 - val_loss: 0.0963\n",
      "Epoch 436/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 8.9915e-05 - val_loss: 0.0967\n",
      "Epoch 437/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 3.7612e-04 - val_loss: 0.0988\n",
      "Epoch 438/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 3.6644e-04 - val_loss: 0.1044\n",
      "Epoch 439/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 8.4923e-04 - val_loss: 0.0960\n",
      "Epoch 440/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0020 - val_loss: 0.1038\n",
      "Epoch 441/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 6.3105e-04 - val_loss: 0.1016\n",
      "Epoch 442/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 6.5759e-04 - val_loss: 0.0996\n",
      "Epoch 443/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0015 - val_loss: 0.1005\n",
      "Epoch 444/500\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 6.7469e-04 - val_loss: 0.0990\n",
      "Epoch 445/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 3.6306e-04 - val_loss: 0.0989\n",
      "Epoch 446/500\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 8.1851e-05 - val_loss: 0.1037\n",
      "Epoch 447/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 4.8370e-04 - val_loss: 0.0989\n",
      "Epoch 448/500\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 2.3275e-04 - val_loss: 0.1015\n",
      "Epoch 449/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 1.0139e-04 - val_loss: 0.1001\n",
      "Epoch 450/500\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1.2456e-04 - val_loss: 0.1053\n",
      "Epoch 451/500\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 2.5526e-04 - val_loss: 0.1044\n",
      "Epoch 452/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 3.0778e-04 - val_loss: 0.1036\n",
      "Epoch 453/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 6.3364e-04 - val_loss: 0.1112\n",
      "Epoch 454/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0015 - val_loss: 0.1090\n",
      "Epoch 455/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 2.7641e-04 - val_loss: 0.1059\n",
      "Epoch 456/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 2.6831e-04 - val_loss: 0.0977\n",
      "Epoch 457/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 9.4413e-05 - val_loss: 0.1013\n",
      "Epoch 458/500\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0013 - val_loss: 0.1022\n",
      "Epoch 459/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0021 - val_loss: 0.0965\n",
      "Epoch 460/500\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 2.3786e-04 - val_loss: 0.0980\n",
      "Epoch 461/500\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 1.2150e-04 - val_loss: 0.0970\n",
      "Epoch 462/500\n",
      "39/41 [===========================>..] - ETA: 0s - loss: 4.9748e-05Restoring model weights from the end of the best epoch: 362.\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 4.8335e-05 - val_loss: 0.0965\n",
      "Epoch 462: early stopping\n"
     ]
    }
   ],
   "source": [
    "class CreateDistanceModel:\n",
    "    def __init__(self, learning_rate=1e-3,decay = None, margin = 0.5 , height = 10, width = 10, channel = 1792):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.margin = margin\n",
    "        self.H = height\n",
    "        self.W = width\n",
    "        self.CH = channel\n",
    "        self.decay = decay\n",
    "        \n",
    "    def distance(self,x,y):\n",
    "        x = K.l2_normalize(x, axis=-1)\n",
    "        y = K.l2_normalize(y, axis=-1)\n",
    "        distance = 1 - K.batch_dot(x, y, axes=-1)\n",
    "        return distance\n",
    "        \n",
    "    def triplet_loss(self,templates):\n",
    "        anchor,positive,negative = templates\n",
    "        positive_distance = self.distance(anchor,positive)\n",
    "        negative_distance = self.distance(anchor,negative)\n",
    "        basic_loss = positive_distance-negative_distance+self.margin\n",
    "        loss = K.maximum(basic_loss,0.0)\n",
    "        return loss\n",
    "\n",
    "    def identity_loss(self,y_true, y_pred):\n",
    "        return K.mean(y_pred)\n",
    "\n",
    "    def __call__(self): \n",
    "        H,W,CH = (self.H, self.W, self.CH) # feature map size\n",
    "        INPUT = layers.Input(shape =(H,W,CH))\n",
    "        # X = layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(INPUT)\n",
    "        # X=layers.UnitNormalization()(INPUT)\n",
    "        # X = layers.Normalization()(INPUT)\n",
    "        X = layers.Conv2D(8,(1,1),padding='same',kernel_initializer='normal',activation='relu')(INPUT)\n",
    "        X = layers.Dropout(0.2)(X)\n",
    "        X = layers.Flatten()(X)\n",
    "        X = layers.Dense(1024,activation = 'relu')(X)\n",
    "        X = layers.Dense(256,activation = 'relu')(X)\n",
    "        Embedding = Model(INPUT, X, name=\"Embedding\")\n",
    "        anchor = layers.Input(shape=(H,W,CH), name='anchor_input')\n",
    "        A = Embedding(anchor)\n",
    "        positive = layers.Input(shape=(H,W,CH), name='positive_input')\n",
    "        P = Embedding(positive)\n",
    "        negative = layers.Input(shape=(H,W,CH), name='negative_input')\n",
    "        N = Embedding(negative)\n",
    "        LOSS = layers.Lambda(self.triplet_loss)([A, P, N])\n",
    "        model = Model(inputs=[anchor,positive,negative],outputs=LOSS)\n",
    "        model.compile(loss=self.identity_loss, optimizer=optimizers.Adamax(learning_rate=self.learning_rate, weight_decay = self.decay))\n",
    "        return model\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "decay = learning_rate / epochs\n",
    "\n",
    "DistClass = CreateDistanceModel(learning_rate=learning_rate,decay=None, margin=0.5, channel = 1792)\n",
    "model = DistClass()\n",
    "model.summary()\n",
    "y_train, y_test, y_val = tf.ones(len(X_train)), tf.ones(len(X_test)), tf.ones(len(X_val))\n",
    "callbacks=[EarlyStopping(patience=100, verbose=1, restore_best_weights=True, monitor='val_loss')]\n",
    "history = model.fit([X_train[:,0],X_train[:,1],X_train[:,2]],y_train,epochs=epochs, batch_size=50,validation_data=([X_val[:,0],X_val[:,1],X_val[:,2]],y_val),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d9364d-ec37-493c-97b2-50c6839ce0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "# plt.figure(figsize=(8,7))\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train_loss','val_loss'], loc='center')\n",
    "# plt.ylim([0, 0.5])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5132a2-83ec-4607-a5e1-5be0b740fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8884462151394422"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def draw_bbox_with_similarity_score (image, od, label,score):\n",
    "    img = image.copy()\n",
    "    h,w = img.shape[:2]\n",
    "    x1 = int(od[0])\n",
    "    y1 = int(od[1])\n",
    "    x2 = int(od[2])\n",
    "    y2 = int(od[3])\n",
    "        \n",
    "    if label == \"anchor\":\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (255,255,255),2)\n",
    "        cv2.putText(img,label, org=(50,50),fontFace=1,fontScale=1, color=(255,255,255))\n",
    "        cv2.putText(img,str(score), org=(20,300),fontFace=1,fontScale=1, color=(255,255,255))\n",
    "    if label == \"positive\":\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0),2)\n",
    "        cv2.putText(img,label, org=(50,50),fontFace=1,fontScale=1, color=(0,255,0))\n",
    "        cv2.putText(img,str(score), org=(200,300),fontFace=1,fontScale=1, color=(0,255,0))\n",
    "    if label == \"negative\":\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,0,255),2)\n",
    "        cv2.putText(img,label, org=(50,50),fontFace=1,fontScale=1, color=(0,0,255))\n",
    "        cv2.putText(img,str(score), org=(200,300),fontFace=1,fontScale=1, color=(0,0,255))\n",
    "    return img\n",
    "\n",
    "def analyze_model(model, X,rgb_dataset,bbox_dataset,show_flag=True):\n",
    "    X_anchor = X[:,0]\n",
    "    X_positive = X[:,1]\n",
    "    X_negative = X[:,2]\n",
    "    siamese_network = model.layers[3]\n",
    "    X_anchor_template = siamese_network.predict(X_anchor)\n",
    "    X_positive_template = siamese_network.predict(X_positive)\n",
    "    X_negative_template = siamese_network.predict(X_negative)\n",
    "    \n",
    "    y_predict_targets_positive = []\n",
    "    for index in range(len(X)):\n",
    "        similarity = cosine_similarity(X_anchor_template[index].reshape(1, -1),X_positive_template[index].reshape(1, -1))\n",
    "        y_predict_targets_positive.append(similarity[0][0])\n",
    "\n",
    "    y_predict_targets_negative = []\n",
    "    for index in range(len(X)):\n",
    "        similarity = cosine_similarity(X_anchor_template[index].reshape(1, -1),X_negative_template[index].reshape(1, -1))\n",
    "        y_predict_targets_negative.append(similarity[0][0])\n",
    "\n",
    "    y_predict_targets_positive = np.array(y_predict_targets_positive)\n",
    "    y_predict_targets_negative = np.array(y_predict_targets_negative)\n",
    "    if show_flag== True:\n",
    "        for index in range(len(rgb_dataset)):\n",
    "            anchor_rgb = rgb_dataset[index][0]\n",
    "            anchor_bbox = bbox_dataset[index][0]\n",
    "            anchor_rgb = draw_bbox_with_similarity_score(anchor_rgb, anchor_bbox,label=\"anchor\", score = \"Cosine Similarity\")\n",
    "            \n",
    "            positive_rgb = rgb_dataset[index][1]\n",
    "            positive_bbox = bbox_dataset[index][1]\n",
    "            positive_rgb = draw_bbox_with_similarity_score(positive_rgb, positive_bbox,label=\"positive\", score = y_predict_targets_positive[index])\n",
    "        \n",
    "            negative_rgb = rgb_dataset[index][2]\n",
    "            negative_bbox = bbox_dataset[index][2]\n",
    "            negative_rgb = draw_bbox_with_similarity_score(negative_rgb, negative_bbox,label=\"negative\", score = y_predict_targets_negative[index])\n",
    "        \n",
    "            flag = show(np.hstack((anchor_rgb,positive_rgb,negative_rgb)))\n",
    "            if flag == -1:\n",
    "                break\n",
    "    y_targets_positive = np.ones((len(X),))\n",
    "    y_targets_negative = np.ones((len(X),))\n",
    "    y_p=(y_predict_targets_positive>=0.5).astype(np.uint8)\n",
    "    y_n=(y_predict_targets_negative<0.5).astype(np.uint8)\n",
    "    return (accuracy_score(y_targets_positive,y_p)+accuracy_score(y_targets_negative,y_n))/2\n",
    "     \n",
    "# analyze_model(model, X_val,rgb_val,bbx_val, show_flag=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2613035a-c669-4814-832a-1042639c22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_model(model, X_test,rgb_test,bbx_test, show_flag=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6855be55-28f3-455a-b01c-5d04c5d6db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_model(model, X_train,rgb_train,bbx_train, show_flag=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8da6f905-89ec-4ff2-89f6-faea7cb87628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphyepyvrj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphyepyvrj/assets\n",
      "/home/shah/.local/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-03-19 12:59:04.348002: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-03-19 12:59:04.348028: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-03-19 12:59:04.348206: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmphyepyvrj\n",
      "2024-03-19 12:59:04.349240: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-03-19 12:59:04.349255: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmphyepyvrj\n",
      "2024-03-19 12:59:04.351790: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-03-19 12:59:04.370156: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmphyepyvrj\n",
      "2024-03-19 12:59:04.376967: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 28762 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train[:,0]).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "siamese_network = model.layers[3]\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(siamese_network)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5cc8480-678d-4507-a7b8-e1a29fbc1692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560944"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_quant_file = tflite_models_dir/\"EmbeddingModel_MobNet_FeatureBased2.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb484ad5-0dc0-429a-8981-5bd3fdbc314d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'serving_default_input_2:0',\n",
       " 'index': 0,\n",
       " 'shape': array([   1,   10,   10, 1792], dtype=int32),\n",
       " 'shape_signature': array([  -1,   10,   10, 1792], dtype=int32),\n",
       " 'dtype': numpy.int8,\n",
       " 'quantization': (1.0, 0),\n",
       " 'quantization_parameters': {'scales': array([1.], dtype=float32),\n",
       "  'zero_points': array([0], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_model_quant_file = tflite_models_dir/\"EmbeddingModel_MobNet_FeatureBased2.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.get_input_details()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd03395f-9957-463a-8448-807a616fe8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'StatefulPartitionedCall:0',\n",
       " 'index': 11,\n",
       " 'shape': array([  1, 256], dtype=int32),\n",
       " 'shape_signature': array([ -1, 256], dtype=int32),\n",
       " 'dtype': numpy.int8,\n",
       " 'quantization': (0.9768680930137634, -128),\n",
       " 'quantization_parameters': {'scales': array([0.9768681], dtype=float32),\n",
       "  'zero_points': array([-128], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40ba86bd-ec31-4130-97bb-914e85015e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwnsq_28t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwnsq_28t/assets\n",
      "/home/shah/.local/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-03-19 12:59:51.470795: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-03-19 12:59:51.470819: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-03-19 12:59:51.471000: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpwnsq_28t\n",
      "2024-03-19 12:59:51.471956: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-03-19 12:59:51.471972: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpwnsq_28t\n",
      "2024-03-19 12:59:51.474074: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-03-19 12:59:51.493328: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpwnsq_28t\n",
      "2024-03-19 12:59:51.500421: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 29421 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "debugger = tf.lite.experimental.QuantizationDebugger(converter=converter, debug_dataset = representative_data_gen)\n",
    "debugger.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c061cd6d-0e85-48d5-aa85-a0703aa05af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function tensorflow.lite.tools.optimize.debugging.python.debugger.QuantizationDebugger._collect_layer_statistics.<locals>.<lambda>()>,\n",
       "            {'NumericVerify/Embedding/conv2d_1/Relu;Embedding/conv2d_1/BiasAdd;Embedding/conv2d_1/Conv2D;Embedding/conv2d_1/BiasAdd/ReadVariableOp1:16': defaultdict(list,\n",
       "                         {'num_elements': 800.0,\n",
       "                          'stddev': 1.7730403,\n",
       "                          'mean_error': -0.16651128,\n",
       "                          'max_abs_error': 7.2843866,\n",
       "                          'mean_squared_error': 3.3062944}),\n",
       "             'NumericVerify/Embedding/flatten/Reshape1:20': defaultdict(list,\n",
       "                         {'num_elements': 800.0,\n",
       "                          'stddev': 1.962091e-06,\n",
       "                          'mean_error': -7.898808e-08,\n",
       "                          'max_abs_error': 1.4801026e-05,\n",
       "                          'mean_squared_error': 3.9889585e-12}),\n",
       "             'NumericVerify/Embedding/dense/MatMul;Embedding/dense/Relu;Embedding/dense/BiasAdd1:24': defaultdict(list,\n",
       "                         {'num_elements': 512.0,\n",
       "                          'stddev': 0.398862,\n",
       "                          'mean_error': 0.0013555896,\n",
       "                          'max_abs_error': 2.021735,\n",
       "                          'mean_squared_error': 0.16854449}),\n",
       "             'NumericVerify/StatefulPartitionedCall:02:28': defaultdict(list,\n",
       "                         {'num_elements': 256.0,\n",
       "                          'stddev': 0.08737916,\n",
       "                          'mean_error': 0.00010247352,\n",
       "                          'max_abs_error': 0.76460546,\n",
       "                          'mean_squared_error': 0.008649626})})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debugger.layer_statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
